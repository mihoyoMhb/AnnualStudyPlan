# AnnualStudyPlan
# 学习计划：3~6 月的紧凑学习与实战

## 目标
- **6 月底前** 掌握 NCNN 框架中至少 60% 常见算子的源码与原理
- 完成 **C++/CMake、并行编程基础** 的学习
- **6 月 9 日前** 兼顾图像学考试复习与课程作业
- 为后续 **CUDA 学习、算子优化及秋招** 打下坚实基础

## 阶段 1：3 月上旬 ~ 3 月中旬
### 1. 环境配置 + 工具熟悉
- 安装 **CMake（>=3.10）**，熟悉 Git 基本命令，为后续编译和管理 NCNN 源码做准备。
- 选择适合的 IDE（VSCode/CLion/Visual Studio 等），配置好调试环境。

### 2. CMake & 现代 C++ 入门
- 通过简单项目掌握 CMakeLists.txt 的常见指令（`add_library`, `add_executable`, `target_link_libraries`, `target_include_directories` 等）。
- 熟悉 C++11/14/17 基本特性（智能指针、lambda、range-based for、std::thread 等），并尝试在小程序中应用。

### 3. NCNN 基础跑通
- 从 **NCNN GitHub** 拉取源码，使用 **CMake** 编译并跑通官方示例（如 `squeezenet.cpp`）。
- 了解 `.param + .bin` 文件的加载方式及推理流程。

### 4. 图像处理基础复习
- 复习 **数字图像处理** 的核心概念：卷积、滤波（Sobel、Canny）、边缘检测、空间域与频率域变换等。
- 为后续理解 **NCNN** 中的卷积、预处理算子，以及 **6 月 9 日的图像学考试** 做准备。

---

## 阶段 2：3 月下旬 ~ 4 月
### 1. 深入 NCNN 核心流程
- 阅读 `src/net.cpp`、`src/layer.cpp` 等源码，了解 **网络加载、层注册、forward 执行流程**。
- 对照官方文档或 Wiki 理解常用 API。

### 2. 阅读重点算子 #1
- 先从 **卷积（`convolution.cpp`）和激活（`relu.cpp`、`sigmoid.cpp`）** 入手，理解数据流与实现细节。
- 若涉及 **并行优化或 SIMD 指令**，查阅 **C++ 多线程/并发编程和 CPU SIMD 指令** 相关资料。

### 3. 结合 C++ 并行
- 使用 **std::thread** 或 **std::mutex** 编写小规模代码，体验并行编程及锁的使用。
- 若感兴趣，可尝试优化 **NCNN 某个简单算子**，测试性能（仅作为练手，避免破坏原功能）。

### 4. 继续巩固 CMake
- 修改官方示例的 `CMakeLists.txt`，或新增源文件，了解如何链接到 **NCNN 库**。

---

## 阶段 3：4 月下旬 ~ 5 月
### 1. 阅读更多常见算子 (50%~60%)
- **Pooling（`pooling.cpp`）：** max pooling / average pooling
- **InnerProduct（全连接）：** 矩阵乘法和权重加载
- **BatchNorm（BN）：** 推理计算（与训练时略有不同）
- **Eltwise：** 加法 / 乘法 / 最大值运算

### 2. 自定义 Layer 实践
- 在 `layer` 目录下新增 `MyLayer.cpp/h` 并注册到 **NCNN**：
  - 自定义 **激活函数 / 滤波操作 / 后处理算子（NMS）**
  - 编译运行后验证其能嵌入 **NCNN 推理流程**

### 3. 图像学考试复习（5 月初强化）
- 结合 **NCNN** 代码中的 **卷积实现**，与课本中的 **卷积 / 滤波器** 知识互相印证。
- 复习往年真题或习题，巩固理论基础，确保 **6 月 9 日考试顺利**。

### 4. 小项目雏形
- **加载一个 MobileNet / YOLO 模型**，在实际图像上运行推理。
- **自己实现前处理（读取、resize、归一化）及后处理（解析结果）**，形成完整 pipeline。

---

## 阶段 4：5 月下旬 ~ 6 月底
### 1. 图像学考试冲刺
- 考前 1~2 周（5 月末 ~ 6 月初）集中复习，完成作业。

### 2. 完善小项目 & 收尾
- 整合 **自定义 Layer**，优化 `CMakeLists.txt`
- **若有 SIMD/多线程优化思路，可尝试实现**
- **最终形成一个 GitHub / 私有仓库演示 demo**

### 3. 总结与展望
- 复盘 **NCNN** 代码，确认掌握 **60%~70%** 算子的流程和原理。
- **整理笔记、博客**，为后续 **CUDA 学习** 做准备。

---

# 长期规划（2025 - 2026）

## 2025 年 7 月 - 9 月：秋招 & CUDA 并行优化
### 1. CUDA 学习与实战
- 学习 **GPU 架构（SM、Warp、Block/Thread）、CUDA 核函数**
- 编写 **矩阵乘法、卷积** 等 demo，使用 **Nsight Prof 分析瓶颈**

### 2. NCNN GPU（Vulkan）对比 CUDA
- 研究 **NCNN** GPU 后端（Vulkan）与 **CUDA（TensorRT、TVM）** 的异同
- 试实现 **CUDA 后端的算子**，对比实验

### 3. 秋招准备
- **优化简历**，突出 **NCNN / CUDA 并行 / 算子优化** 经验
- **刷算法题、复习计算机基础（OS / 网络 / GPU）**

### 4. 量化 & 大模型推理（可选）
- 研究 **INT8/INT4 量化、模型剪枝、大模型推理（LLaMA）**
- **学习 Fusion / 计算图优化技巧**

---

## 2025 年 10 月 - 2026 年 3 月：毕业论文 & PhD 申请
### 1. 毕业论文方向
- 结合 **NCNN / GPU 方向** 进行论文研究
- 对比不同 **优化方法 / 算子性能提升**

### 2. 开源社区贡献
- **贡献 PR / 修复 Bug / 撰写文档**（NCNN, TVM, MegEngine）
- 提高 **简历竞争力 & PhD 申请优势**

### 3. 申请 PhD（备选）
- **准备 TOEFL/IELTS/GRE、推荐信、研究计划书**
- 提前联系 **潜在导师**

---

# 2026 年 4 月 - 毕业后
### 若已拿到 Offer
- **完成毕业论文**，正式入职
- 继续深耕 **GPU 并行、算子优化、大模型推理**

### 若继续读 PhD
- **2026 年 7 月入学**，开始博士研究
- **NCNN / CUDA 经验** 将是极好基础

---

# 结语
- **3~6 月：扎实 C++/CMake + NCNN**
- **7~9 月：系统学 CUDA，秋招冲刺**
- **10 月后：择业 or PhD 申请，持续成长**
